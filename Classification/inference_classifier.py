import tensorflow as tf
from keras.models import load_model
import numpy as np
import pandas as pd
import argparse
import os
import math
import csv
import gc
tf.config.run_functions_eagerly(True)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", help='The path to the classification model', default='model/model_ResNet50.h5')
    parser.add_argument("--img_size", help='The size of the images in length*width', default='224*224')
    parser.add_argument("--data", help='The path to the image crops generated by the tracking module', default="../campagne/tracking")
    parser.add_argument("--max_img_in_memory", help='The number of croped images loaded in memory at the same time', default=2000)
    args = parser.parse_args()
    model = load_model(args.model)
    model.compile(run_eagerly=True)
    size = args.img_size
    length, width = size.split("*")
    datafile = args.data
    max_img_in_memory = args.max_img_in_memory

    #listing all crops to a csv file
    crop_files = ["path;id"]
    
    for root, dirs, files in os.walk(datafile):
        for file_name in files:
            file_path = os.path.join(root, file_name)
            if 'crops' in file_path:
                id = (file_path.split('crops/')[1]).split('/')[1]
                crop_files.append(file_path+';'+id)
    with open("data.csv", 'w') as csv_file:
        writer = csv.writer(csv_file)
        for data in crop_files:
            writer.writerow([data])
    
    df = pd.read_csv('data.csv', sep=';')
    total_rows = len(df)
    num_chunks = math.ceil(total_rows / int(max_img_in_memory))
    chunks = np.array_split(df, num_chunks)
    
    #initiate csv_file
    df = pd.DataFrame(columns=["path","id","category"])
    df.to_csv("inference_results.csv", index=False)
    
    for chunk in chunks:
        X = []
        for index,row in enumerate(chunk.iterrows()):
            image_name = row[1]['path']
            image= tf.keras.preprocessing.image.load_img(image_name, color_mode='rgb', target_size=(int(length), int(width)))
            image= np.array(image)
            X.append(image)
        X = np.array(X)
        
        predictions = model.predict(X)
        chunk['category'] = np.argmax(predictions, axis=1)
        chunk.to_csv("inference_results.csv", mode='a', header=False, index=False)
        
        del X
        del predictions
        gc.collect()

    df = pd.read_csv("inference_results.csv", sep= ',')
    
    # Define a single class for each vehicle id with majority voting
    vehicle_df = pd.DataFrame(columns=df.columns)
    for vehicle_id in set(df['id']):
        current_vehicle_df = df[df['id'] == vehicle_id]
        vehicle_df = pd.concat([vehicle_df, pd.DataFrame([[current_vehicle_df['path'].iloc[0],
                                            current_vehicle_df['id'].iloc[0],
                                            current_vehicle_df['category'].mode()[0]]], columns=df.columns.values)])

    vehicle_df.to_csv("inference_results.csv", index=False) 
